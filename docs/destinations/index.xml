<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Datacord Documentation â€“ Destinations Overview</title><link>https://docs.datacord.io/docs/destinations/</link><description>Recent content in Destinations Overview on Datacord Documentation</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://docs.datacord.io/docs/destinations/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: BigQuery Destination</title><link>https://docs.datacord.io/docs/destinations/bigquery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.datacord.io/docs/destinations/bigquery/</guid><description>
&lt;p>BigQuery is a fully managed, serverless data warehouse that enables scalable analysis over petabytes of data. As a destination, it can store data and allow you to perform data analytics tasks and create dashboards in popular BI tools such as Looker Studio, PowerBI, Tableau, etc.&lt;/p>
&lt;h2 id="create-google-cloud-platform-gcp-service-account">Create Google Cloud Platform (GCP) service account&lt;/h2>
&lt;p>To stream data into BigQuery, create a GCP service account and its access key. Follow these steps:&lt;/p>
&lt;ol>
&lt;li>Create a service account by following the instructions &lt;a href="https://cloud.google.com/iam/docs/service-accounts-create">here&lt;/a>.&lt;/li>
&lt;li>Assign the &lt;strong>BigQuery Data Owner&lt;/strong> role to the account.&lt;/li>
&lt;li>Create a key for the service account and download the JSON key file using the instructions &lt;a href="https://cloud.google.com/iam/docs/keys-create-delete#creating">here&lt;/a>.&lt;/li>
&lt;/ol>
&lt;h2 id="create-bigquery-dataset">Create BigQuery dataset&lt;/h2>
&lt;p>Create a new BigQuery dataset in the GCP project where you created the service account.&lt;/p>
&lt;h2 id="create-bigquery-destination">Create BigQuery destination&lt;/h2>
&lt;p>Go to the user interface and create a &lt;strong>BigQuery&lt;/strong> destination. In the destination settings, copy and paste the content of the service account key JSON file into the &lt;strong>GCP Service Account Key (JSON)&lt;/strong> field. Set the GCP project name and dataset name. These settings will allow the system to create tables and views, and stream data into them.&lt;/p>
&lt;p>The system will create an &lt;code>events&lt;/code> table with &lt;code>local_date&lt;/code> as the day partition field. It is important to set the correct timezone for the destination to ensure events are partitioned correctly.&lt;/p>
&lt;h2 id="configure-the-events">Configure the events&lt;/h2>
&lt;p>The system creates two tables: &lt;code>events&lt;/code> and &lt;code>users&lt;/code>. The &lt;code>events&lt;/code> table contains all the streamed events, while the &lt;code>users&lt;/code> table contains the relationship between the &lt;code>identifier&lt;/code> and the first-party &lt;code>user_id&lt;/code>.&lt;/p>
&lt;p>For each event type, the system creates a view once the event is streamed to the destination. For example, the &lt;code>pageview&lt;/code> view contains all &lt;code>pageview&lt;/code> events consolidated by &lt;code>user_id&lt;/code>. If a user has used two devices to browse your website and they are identified on both devices, the &lt;code>pageview&lt;/code> table will have the same &lt;code>user_id&lt;/code> attached to the &lt;code>pageview&lt;/code> events on both devices.&lt;/p>
&lt;p>In the system user interface, click on the BigQuery destination to view all the events that are streamed to your BigQuery dataset. The &lt;code>events&lt;/code> table allows 50 custom variable slots. Click the &lt;strong>Update&lt;/strong> button of an event to manage the variables. You can enable and disable variables, change their data types, and the mapping slot. Please note that not all variables sent with the event are enabled by default. You can toggle the setting to &lt;strong>Show All&lt;/strong> to see and manage the disabled variables.&lt;/p></description></item><item><title>Docs: PubSub Destination</title><link>https://docs.datacord.io/docs/destinations/pubsub/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.datacord.io/docs/destinations/pubsub/</guid><description>
&lt;p>Google PubSub is a messaging service provided by Google Cloud. It enables asynchronous communication between applications using topics and subscriptions. Subscribers who have subscribed to a topic can receive messages published to that topic.&lt;/p>
&lt;p>PubSub offers reliable and scalable messaging, making it suitable for various use cases such as real-time analytics, event-driven architectures, and decoupled microservices.&lt;/p>
&lt;h2 id="create-a-google-cloud-platform-gcp-service-account">Create a Google Cloud Platform (GCP) service account&lt;/h2>
&lt;p>To stream data into BigQuery, create a GCP service account and its access key. Follow these steps:&lt;/p>
&lt;ol>
&lt;li>Create a service account by following the instructions &lt;a href="https://cloud.google.com/iam/docs/service-accounts-create">here&lt;/a>.&lt;/li>
&lt;li>Assign the &lt;strong>Pub/Sub Publisher&lt;/strong> role to the account.&lt;/li>
&lt;li>Create a key for the service account and download the JSON key file using the instructions &lt;a href="https://cloud.google.com/iam/docs/keys-create-delete#creating">here&lt;/a>.&lt;/li>
&lt;/ol>
&lt;h2 id="create-pubsub-topics">Create PubSub topic(s)&lt;/h2>
&lt;p>The PubSub destination supports two modes:&lt;/p>
&lt;ol>
&lt;li>Streaming all events to a single PubSub topic.&lt;/li>
&lt;li>Streaming events to a topic named after the event type. For example, all &lt;code>pageview&lt;/code> events will be streamed to the &lt;code>events&lt;/code> topic, while all &lt;code>web_click&lt;/code> events will be streamed to the &lt;code>web_click&lt;/code> topic.&lt;/li>
&lt;/ol>
&lt;p>Depending on the mode you choose, create the necessary topic name(s). For the second mode, which is specific to each event type, you can set up the schema to map the variables of the event&amp;rsquo;s data.&lt;/p>
&lt;h2 id="create-pubsub-destination">Create PubSub destination&lt;/h2>
&lt;p>Go to the user interface and create a &lt;em>Pub/Sub&lt;/em> destination. In the destination settings, copy and paste the content of the service account key JSON file into the &lt;strong>GCP Service Account Key (JSON)&lt;/strong> field. Set the GCP project name. These settings allow the system to send the events to your Pub/Sub topics.&lt;/p></description></item></channel></rss>